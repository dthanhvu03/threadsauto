#!/usr/bin/env python3
"""
Script archive jobs c≈© (completed > X ng√†y) v√†o th∆∞ m·ª•c archive.

Usage:
    python scripts/archive_old_jobs.py [--jobs-dir jobs/] [--archive-dir archive/] [--days 30] [--dry-run]
"""

import json
import sys
import shutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List

# Setup path using common utility
from scripts.common import setup_path, print_header, print_section

# Add parent directory to path (must be after importing common)
setup_path()


def archive_old_jobs(
    jobs_dir: Path,
    archive_dir: Path,
    days: int = 30,
    dry_run: bool = False
) -> int:
    """
    Archive jobs completed c≈© h∆°n X ng√†y.
    
    Returns:
        S·ªë l∆∞·ª£ng jobs ƒë√£ archive
    """
    archive_dir.mkdir(parents=True, exist_ok=True)
    
    cutoff_date = datetime.now() - timedelta(days=days)
    print(f"üìÖ Archive jobs completed tr∆∞·ªõc: {cutoff_date.strftime('%Y-%m-%d')}")
    print()
    
    job_files = sorted(jobs_dir.glob("jobs_*.json"))
    archived_count = 0
    files_updated = 0
    
    for job_file in job_files:
        try:
            with open(job_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            jobs = data.get('jobs', [])
            jobs_to_archive = []
            jobs_to_keep = []
            
            for job in jobs:
                status = job.get('status', '')
                completed_at = job.get('completed_at')
                
                # Ch·ªâ archive completed jobs c≈©
                if status == 'completed' and completed_at:
                    try:
                        completed_dt = datetime.fromisoformat(completed_at.replace('Z', '+00:00'))
                        if completed_dt < cutoff_date:
                            jobs_to_archive.append(job)
                            archived_count += 1
                        else:
                            jobs_to_keep.append(job)
                    except:
                        # N·∫øu kh√¥ng parse ƒë∆∞·ª£c date, gi·ªØ l·∫°i
                        jobs_to_keep.append(job)
                else:
                    # Gi·ªØ l·∫°i jobs ch∆∞a completed
                    jobs_to_keep.append(job)
            
            if jobs_to_archive:
                # L∆∞u v√†o archive file
                archive_file = archive_dir / job_file.name
                
                if archive_file.exists():
                    # Merge v·ªõi archive file hi·ªán c√≥
                    with open(archive_file, 'r', encoding='utf-8') as f:
                        archive_data = json.load(f)
                    archive_data['jobs'].extend(jobs_to_archive)
                else:
                    archive_data = {
                        'jobs': jobs_to_archive,
                        'archived_at': datetime.now().isoformat(),
                        'archived_from': job_file.name,
                        'cutoff_date': cutoff_date.isoformat()
                    }
                
                if not dry_run:
                    with open(archive_file, 'w', encoding='utf-8') as f:
                        json.dump(archive_data, f, indent=2, ensure_ascii=False)
                
                print(f"   üì¶ {job_file.name}: Archive {len(jobs_to_archive)} jobs ‚Üí {archive_file.name}")
                
                # Update file g·ªëc (ch·ªâ gi·ªØ jobs c√≤n l·∫°i)
                if not dry_run:
                    data['jobs'] = jobs_to_keep
                    data['updated_at'] = datetime.now().isoformat()
                    
                    # Atomic write
                    temp_file = job_file.with_suffix('.json.tmp')
                    with open(temp_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, indent=2, ensure_ascii=False)
                    temp_file.replace(job_file)
                    
                    files_updated += 1
        
        except Exception as e:
            print(f"   ‚ùå L·ªói x·ª≠ l√Ω file {job_file.name}: {str(e)}")
    
    print()
    if dry_run:
        print(f"üîç DRY RUN: S·∫Ω archive {archived_count} jobs")
    else:
        print(f"‚úÖ Ho√†n th√†nh! ƒê√£ archive {archived_count} jobs v√†o {archive_dir}")
        print(f"   ‚Üí Updated {files_updated} files")
    
    return archived_count


def main():
    """Main function."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Archive jobs completed c≈©"
    )
    parser.add_argument(
        "--jobs-dir",
        type=str,
        default="jobs/",
        help="Th∆∞ m·ª•c ch·ª©a jobs (m·∫∑c ƒë·ªãnh: jobs/)"
    )
    parser.add_argument(
        "--archive-dir",
        type=str,
        default="jobs/archive/",
        help="Th∆∞ m·ª•c archive (m·∫∑c ƒë·ªãnh: jobs/archive/)"
    )
    parser.add_argument(
        "--days",
        type=int,
        default=30,
        help="S·ªë ng√†y ƒë·ªÉ coi l√† 'c≈©' (m·∫∑c ƒë·ªãnh: 30)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Ch·ªâ hi·ªÉn th·ªã s·∫Ω archive g√¨, kh√¥ng th·ª±c s·ª± archive"
    )
    
    args = parser.parse_args()
    
    jobs_dir = Path(args.jobs_dir)
    if not jobs_dir.exists():
        print(f"‚ùå Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: {jobs_dir}")
        return
    
    if args.dry_run:
        print("üîç DRY RUN MODE - Kh√¥ng th·ª±c s·ª± archive jobs")
        print()
    
    archive_old_jobs(
        jobs_dir=jobs_dir,
        archive_dir=Path(args.archive_dir),
        days=args.days,
        dry_run=args.dry_run
    )


if __name__ == "__main__":
    main()

