"""
Module: services/scheduler/execution.py

Execution logic cho scheduler: run_job, scheduler_loop.
"""

# Standard library
import sys
from pathlib import Path

# Add parent directory to path ƒë·ªÉ c√≥ th·ªÉ import utils modules
_parent_dir = Path(__file__).resolve().parent.parent.parent
_parent_dir_str = str(_parent_dir)
if _parent_dir_str not in sys.path:
    sys.path.insert(0, _parent_dir_str)
elif sys.path[0] != _parent_dir_str:
    sys.path.remove(_parent_dir_str)
    sys.path.insert(0, _parent_dir_str)

import asyncio
from datetime import datetime, timedelta
from typing import Dict, Callable, Any

# Local
from services.logger import StructuredLogger
from services.exceptions import StorageError
from services.scheduler.models import ScheduledJob, JobStatus, Platform, JobType
from services.safety_guard import RiskLevel, get_shared_safety_guard
from utils.exception_utils import (
    safe_get_exception_type_name,
    safe_get_exception_message,
    format_exception
)


class JobExecutor:
    """
    Job executor cho scheduler.
    
    X·ª≠ l√Ω execution logic:
    - Run individual jobs
    - Scheduler loop
    """
    
    def __init__(
        self,
        jobs: Dict[str, ScheduledJob],
        logger: StructuredLogger,
        save_callback: Callable[[], None]
    ):
        """
        Kh·ªüi t·∫°o job executor.
        
        Args:
            jobs: Dict mapping job_id -> ScheduledJob
            logger: Logger instance
            save_callback: Callback ƒë·ªÉ save jobs
        """
        self.jobs = jobs
        self.logger = logger
        self.save_jobs = save_callback
        self._last_save_time = datetime.min  # Track save time ƒë·ªÉ tr√°nh reload ngay sau save

        # Safety guard d√πng singleton shared (ƒë·ªìng b·ªô v·ªõi UI/SafetyAPI)
        self.safety_guard = get_shared_safety_guard(logger=self.logger)
    
    def _update_job_status(self, job: ScheduledJob, message: str) -> None:
        """
        Update job status message v√† save ngay l·∫≠p t·ª©c ƒë·ªÉ UI c√≥ th·ªÉ hi·ªÉn th·ªã real-time.
        
        Args:
            job: Job c·∫ßn update
            message: Status message m·ªõi
        """
        job.status_message = message
        try:
            self.save_jobs()
            self._last_save_time = datetime.now()
        except StorageError as e:
            # Log warning nh∆∞ng kh√¥ng raise (ƒë·ªÉ kh√¥ng block execution)
            self.logger.log_step(
                step="UPDATE_JOB_STATUS",
                result="WARNING",
                job_id=job.job_id,
                error=f"Failed to save status update: {str(e)}",
                error_type="StorageError"
            )
    
    async def run_job(
        self,
        job: ScheduledJob,
        post_callback_factory: Callable[[Platform], Callable[[str, str, Callable[[str], None]], Any]]
    ) -> None:
        """
        Ch·∫°y m·ªôt job.
        
        Args:
            job: Job c·∫ßn ch·∫°y
            post_callback_factory: Factory function ƒë·ªÉ l·∫•y callback d·ª±a tr√™n platform
                                  Callback nh·∫≠n (account_id, content, status_updater)
        """
        # --- SAFETY CHECK TR∆Ø·ªöC KHI CH·∫†Y JOB ---
        # Ch·ªâ check safety guard cho POST jobs, engagement jobs c√≥ safety guard ri√™ng
        job_type = getattr(job, 'job_type', JobType.POST)
        if job_type == JobType.POST:
            allowed, safety_error, risk_level = self.safety_guard.can_post(job.account_id, job.content)
            if not allowed:
                # Block job theo SafetyGuard
                job.status = JobStatus.FAILED
                job.error = safety_error
                job.status_message = f"‚ùå B·ªã ch·∫∑n b·ªüi SafetyGuard (risk={risk_level.value}): {safety_error}"
                job.completed_at = datetime.now()

                # Ghi nh·∫≠n high-risk n·∫øu m·ª©c ƒë·ªô cao
                if risk_level in (RiskLevel.HIGH, RiskLevel.CRITICAL):
                    self.safety_guard.record_high_risk_event(job.account_id, "scheduler_post_blocked")

                self.logger.log_step(
                    step="RUN_JOB_SAFETY_CHECK",
                    result="BLOCKED",
                    job_id=job.job_id,
                    account_id=job.account_id,
                    error=safety_error,
                    risk_level=risk_level.value,
                    status_message=job.status_message
                )

                # Save ngay ƒë·ªÉ UI th·∫•y tr·∫°ng th√°i
                try:
                    self.save_jobs()
                    self._last_save_time = datetime.now()
                except StorageError as e:
                    self.logger.log_step(
                        step="RUN_JOB_SAFETY_CHECK",
                        result="WARNING",
                        job_id=job.job_id,
                        error=f"Failed to save blocked job: {safe_get_exception_message(e)}",
                        error_type=safe_get_exception_type_name(e)
                    )
                return

        # --- B·∫ÆT ƒê·∫¶U TH·ª∞C THI JOB ---
        job.status = JobStatus.RUNNING
        job.started_at = datetime.now()  # L∆∞u th·ªùi gian b·∫Øt ƒë·∫ßu ch·∫°y
        self._update_job_status(job, "üîÑ ƒêang kh·ªüi ƒë·ªông browser...")
        
        # Create WebSocketLogger for realtime job execution logs
        try:
            from services.websocket_logger import WebSocketLogger
            ws_logger = WebSocketLogger(
                logger=self.logger,
                room="scheduler",
                account_id=job.account_id
            )
        except Exception:
            # Fallback to regular logger if WebSocketLogger not available
            ws_logger = self.logger
        
        try:
            # Log job start via WebSocket
            if hasattr(ws_logger, 'log_start'):
                await ws_logger.log_start(
                    operation="run_job",
                    account_id=job.account_id,
                    job_id=job.job_id
                )
            
            self.logger.log_step(
                step="RUN_JOB",
                result="IN_PROGRESS",
                job_id=job.job_id,
                account_id=job.account_id,
                retry_count=job.retry_count,
                status_message=job.status_message
            )
            
            # T·∫°o status updater callback ƒë·ªÉ pass v√†o callback
            def status_updater(message: str) -> None:
                """Update job status message."""
                self._update_job_status(job, message)
            
            # Ph√¢n bi·ªát job type: POST ho·∫∑c ENGAGEMENT
            job_type = getattr(job, 'job_type', JobType.POST)
            
            if job_type == JobType.ENGAGEMENT:
                # Engagement job: Parse engagement_data v√† g·ªçi engagement callback
                import json
                engagement_data = getattr(job, 'engagement_data', None)
                if not engagement_data:
                    raise ValueError(f"Engagement job {job.job_id} missing engagement_data")
                
                # Parse engagement_data n·∫øu l√† string
                if isinstance(engagement_data, str):
                    engagement_data = json.loads(engagement_data)
                
                action_type = engagement_data.get('action_type', '').lower()
                
                # Import engagement callback factory
                try:
                    from backend.app.modules.scheduler.utils.engagement_callback_factory import create_engagement_callback_factory
                    engagement_callback_factory = create_engagement_callback_factory()
                    engagement_callback = engagement_callback_factory(action_type)
                except ImportError:
                    # Fallback: Import directly from threads.engagement.callbacks
                    from threads.engagement.callbacks import like_callback, comment_callback, follow_callback
                    from threads.engagement.types import EngagementAction
                    
                    if action_type == 'like':
                        engagement_callback = like_callback
                    elif action_type == 'comment':
                        engagement_callback = comment_callback
                    elif action_type == 'follow':
                        engagement_callback = follow_callback
                    else:
                        raise ValueError(f"Unknown engagement action_type: {action_type}")
                
                # Prepare criteria from engagement_data
                if action_type == 'like':
                    from threads.engagement.types import LikeCriteria
                    criteria = LikeCriteria(**engagement_data.get('like_criteria', {}))
                    result = await engagement_callback(job.account_id, criteria, status_updater)
                elif action_type == 'comment':
                    from threads.engagement.types import CommentCriteria
                    criteria = CommentCriteria(**engagement_data.get('comment_criteria', {}))
                    result = await engagement_callback(job.account_id, criteria, status_updater)
                elif action_type == 'follow':
                    from threads.engagement.types import FollowCriteria
                    criteria = FollowCriteria(**engagement_data.get('follow_criteria', {}))
                    result = await engagement_callback(job.account_id, criteria, status_updater)
                else:
                    raise ValueError(f"Unknown engagement action_type: {action_type}")
                
                # Engagement callbacks return List[EngagementResult] ho·∫∑c EngagementResult
                # Convert to compatible format
                if isinstance(result, list):
                    # List of results - check if all succeeded
                    success_count = sum(1 for r in result if r.success)
                    total_count = len(result)
                    success = success_count > 0
                    # Create a simple result object
                    from types import SimpleNamespace
                    result = SimpleNamespace(
                        success=success,
                        thread_id=None,
                        error=None if success else f"Only {success_count}/{total_count} actions succeeded"
                    )
                elif hasattr(result, 'success'):
                    # Single EngagementResult
                    from types import SimpleNamespace
                    result = SimpleNamespace(
                        success=result.success,
                        thread_id=result.target_id,
                        error=result.error
                    )
            else:
                # POST job: Use existing post callback
                platform = getattr(job, 'platform', Platform.THREADS)
                post_callback = post_callback_factory(platform)
                
                # L·∫•y link_aff t·ª´ job (n·∫øu c√≥)
                link_aff = getattr(job, 'link_aff', None)
                
                # G·ªçi callback ƒë·ªÉ ƒëƒÉng b√†i (pass status_updater v√† link_aff)
                result = await post_callback(job.account_id, job.content, status_updater, link_aff)
            
            # Validate result object
            if not hasattr(result, 'success'):
                raise ValueError(f"post_callback result must have 'success' attribute, got {type(result)}")
            
            if result.success:
                job.status = JobStatus.COMPLETED
                job.completed_at = datetime.now()
                job.thread_id = result.thread_id if hasattr(result, 'thread_id') else None
                job.status_message = f"Ho√†n th√†nh th√†nh c√¥ng - Thread ID: {job.thread_id or 'N/A'}"

                # Log job completion via WebSocket
                if hasattr(ws_logger, 'log_complete'):
                    await ws_logger.log_complete(
                        operation="run_job",
                        success=True,
                        result={"thread_id": job.thread_id},
                        account_id=job.account_id,
                        job_id=job.job_id
                    )

                # Ghi nh·∫≠n success cho SafetyGuard ƒë·ªÉ reset counters / c·∫≠p nh·∫≠t health
                try:
                    self.safety_guard.record_post_success(job.account_id, job.content)
                except Exception:
                    # Kh√¥ng ƒë·ªÉ l·ªói safety ·∫£nh h∆∞·ªüng k·∫øt qu·∫£ job
                    pass
                
                # QUAN TR·ªåNG: Save ngay sau khi job completed ƒë·ªÉ ƒë·∫£m b·∫£o persistence v√† realtime update
                # Kh√¥ng ƒë·ª£i ƒë·∫øn finally block ƒë·ªÉ tr√°nh m·∫•t d·ªØ li·ªáu n·∫øu c√≥ exception
                # File JSON s·∫Ω ƒë∆∞·ª£c c·∫≠p nh·∫≠t realtime ngay sau khi post th√†nh c√¥ng
                try:
                    save_start_time = datetime.now()
                    self.save_jobs()
                    save_duration = (datetime.now() - save_start_time).total_seconds() * 1000
                    self._last_save_time = datetime.now()
                    self.logger.log_step(
                        step="RUN_JOB",
                        result="SUCCESS",
                        job_id=job.job_id,
                        thread_id=job.thread_id,
                        status_message=job.status_message,
                        save_duration_ms=save_duration,
                        note="Job completed and saved immediately (realtime update)"
                    )
                except Exception as save_error:
                    # Log error nh∆∞ng kh√¥ng fail job (job ƒë√£ completed th√†nh c√¥ng)
                    self.logger.log_step(
                        step="RUN_JOB",
                        result="WARNING",
                        job_id=job.job_id,
                        error=f"Job completed but failed to save immediately: {safe_get_exception_message(save_error)}",
                        error_type=safe_get_exception_type_name(save_error),
                        thread_id=job.thread_id,
                        status_message=job.status_message
                    )
                    # V·∫´n log success ƒë·ªÉ track job ƒë√£ completed
                    self.logger.log_step(
                        step="RUN_JOB",
                        result="SUCCESS",
                        job_id=job.job_id,
                        thread_id=job.thread_id,
                        status_message=job.status_message,
                        note="Job completed (save will retry in finally block)"
                    )
            else:
                # Th·ª≠ retry n·∫øu c√≥ th·ªÉ
                if job.can_retry():
                    job.retry_count += 1
                    job.status = JobStatus.SCHEDULED
                    # Exponential backoff: 2^retry_count minutes
                    backoff_minutes = 2 ** job.retry_count
                    job.scheduled_time = datetime.now() + timedelta(minutes=backoff_minutes)
                    # Safely get error message
                    error_msg = getattr(result, 'error', 'Unknown error')
                    job.status_message = f"Th·∫•t b·∫°i, s·∫Ω th·ª≠ l·∫°i sau {backoff_minutes} ph√∫t (l·∫ßn th·ª≠ {job.retry_count}/{job.max_retries}) - L·ªói: {error_msg}"
                    
                    self.logger.log_step(
                        step="RUN_JOB",
                        result="RETRY_SCHEDULED",
                        job_id=job.job_id,
                        retry_count=job.retry_count,
                        next_run=job.scheduled_time.isoformat(),
                        error=error_msg,
                        status_message=job.status_message
                    )
                else:
                    job.status = JobStatus.FAILED
                    # Safely get error message
                    error_msg = getattr(result, 'error', 'Unknown error')
                    job.error = error_msg
                    job.status_message = f"Th·∫•t b·∫°i ho√†n to√†n sau {job.retry_count} l·∫ßn th·ª≠ - {error_msg}"

                    # Log job error via WebSocket
                    if hasattr(ws_logger, 'log_error'):
                        await ws_logger.log_error(
                            operation="run_job",
                            error=error_msg,
                            error_type="PostError",
                            account_id=job.account_id,
                            job_id=job.job_id
                        )

                    # Ghi nh·∫≠n l·ªói cho SafetyGuard
                    try:
                        self.safety_guard.record_post_error(
                            job.account_id,
                            error_type="PostError",
                            error_message=error_msg
                        )
                    except Exception:
                        pass
                    self.logger.log_step(
                        step="RUN_JOB",
                        result="FAILED",
                        job_id=job.job_id,
                        error=result.error,
                        retry_count=job.retry_count,
                        status_message=job.status_message
                    )
        
        except Exception as e:
            # Th·ª≠ retry n·∫øu c√≥ th·ªÉ
            if job.can_retry():
                job.retry_count += 1
                job.status = JobStatus.SCHEDULED
                backoff_minutes = 2 ** job.retry_count
                job.scheduled_time = datetime.now() + timedelta(minutes=backoff_minutes)
                error_formatted = format_exception(e)
                job.status_message = f"L·ªói exception, s·∫Ω th·ª≠ l·∫°i sau {backoff_minutes} ph√∫t (l·∫ßn th·ª≠ {job.retry_count}/{job.max_retries}) - {error_formatted}"
                
                self.logger.log_step(
                    step="RUN_JOB",
                    result="RETRY_SCHEDULED",
                    job_id=job.job_id,
                    retry_count=job.retry_count,
                    next_run=job.scheduled_time.isoformat(),
                    error=safe_get_exception_message(e),
                    error_type=safe_get_exception_type_name(e),
                    status_message=job.status_message
                )
            else:
                job.status = JobStatus.FAILED
                error_formatted = format_exception(e)
                job.error = error_formatted
                job.status_message = f"L·ªói kh√¥ng th·ªÉ retry sau {job.retry_count} l·∫ßn th·ª≠ - {error_formatted}"

                # Log job error via WebSocket
                try:
                    if hasattr(ws_logger, 'log_error'):
                        await ws_logger.log_error(
                            operation="run_job",
                            error=safe_get_exception_message(e),
                            error_type=safe_get_exception_type_name(e),
                            account_id=job.account_id,
                            job_id=job.job_id
                        )
                except Exception:
                    pass

                # Ghi nh·∫≠n l·ªói exception cho SafetyGuard
                try:
                    self.safety_guard.record_post_error(
                        job.account_id,
                        error_type=safe_get_exception_type_name(e),
                        error_message=safe_get_exception_message(e)
                    )
                except Exception:
                    pass
                self.logger.log_step(
                    step="RUN_JOB",
                    result="ERROR",
                    job_id=job.job_id,
                    error=safe_get_exception_message(e),
                    error_type=safe_get_exception_type_name(e),
                    retry_count=job.retry_count,
                    status_message=job.status_message
                )
        
        finally:
            # Save jobs v·ªõi error handling
            try:
                self.save_jobs()
                # Track save time ƒë·ªÉ tr√°nh reload ngay sau save
                self._last_save_time = datetime.now()
            except StorageError as e:
                # Log warning nh∆∞ng kh√¥ng raise
                self.logger.log_step(
                    step="RUN_JOB",
                    result="WARNING",
                    job_id=job.job_id,
                    error=f"Failed to save job in finally block: {str(e)}",
                    error_type="StorageError"
                )
            except Exception as e:
                # Log error nh∆∞ng kh√¥ng raise (ƒë·ªÉ ƒë·∫£m b·∫£o job state ƒë∆∞·ª£c update)
                self.logger.log_step(
                    step="RUN_JOB",
                    result="ERROR",
                    job_id=job.job_id,
                    error=f"Unexpected error saving job in finally block: {safe_get_exception_message(e)}",
                    error_type=safe_get_exception_type_name(e)
                )
    
    async def scheduler_loop(
        self,
        post_callback_factory: Callable[[Platform], Callable[[str, str], Any]],
        running_flag_getter: Callable[[], bool],
        running_flag_setter: Callable[[bool], None],
        get_ready_jobs: Callable[[], list],
        cleanup_expired_jobs: Callable[[], int],
        recover_stuck_jobs: Callable[[], int],
        reload_jobs_callback: Callable[[], None] | None = None,
        get_last_save_time: Callable[[], datetime] | None = None
    ) -> None:
        """
        V√≤ng l·∫∑p scheduler ch√≠nh.
        
        Args:
            post_callback_factory: Factory function ƒë·ªÉ l·∫•y callback d·ª±a tr√™n platform
            running_flag_getter: Function ƒë·ªÉ check running flag
            running_flag_setter: Function ƒë·ªÉ set running flag
            get_ready_jobs: Function ƒë·ªÉ l·∫•y ready jobs
            cleanup_expired_jobs: Function ƒë·ªÉ cleanup expired jobs
            recover_stuck_jobs: Function ƒë·ªÉ recover stuck jobs
            reload_jobs_callback: Optional callback ƒë·ªÉ reload jobs t·ª´ storage (ƒë·ªÉ pick up jobs m·ªõi)
        """
        while running_flag_getter():
            try:
                # Check running flag ngay ƒë·∫ßu loop ƒë·ªÉ c√≥ th·ªÉ exit nhanh
                if not running_flag_getter():
                    self.logger.log_step(
                        step="SCHEDULER_LOOP",
                        result="INFO",
                        note="Scheduler running flag set to False, exiting loop"
                    )
                    break
                
                # Cleanup expired jobs v·ªõi error handling
                try:
                    cleanup_expired_jobs()
                    # Track save time n·∫øu cleanup c√≥ save jobs
                    if hasattr(cleanup_expired_jobs, '__self__') and hasattr(cleanup_expired_jobs.__self__, '_last_save_time'):
                        self._last_save_time = cleanup_expired_jobs.__self__._last_save_time
                except Exception as e:
                    self.logger.log_step(
                        step="SCHEDULER_LOOP",
                        result="WARNING",
                        error=f"Error in cleanup_expired_jobs: {safe_get_exception_message(e)}",
                        error_type=safe_get_exception_type_name(e)
                    )
                
                # Recover stuck jobs (jobs RUNNING qu√° l√¢u do crash/m·∫•t m·∫°ng) v·ªõi error handling
                try:
                    recover_stuck_jobs()
                except Exception as e:
                    self.logger.log_step(
                        step="SCHEDULER_LOOP",
                        result="WARNING",
                        error=f"Error in recover_stuck_jobs: {safe_get_exception_message(e)}",
                        error_type=safe_get_exception_type_name(e)
                    )
                
                # Ki·ªÉm tra xem c√≥ job n√†o ƒëang RUNNING kh√¥ng
                # Scheduler ch·ªâ n√™n ch·∫°y 1 job t·∫°i m·ªôt th·ªùi ƒëi·ªÉm
                try:
                    running_jobs = [j for j in self.jobs.values() if j.status == JobStatus.RUNNING]
                except (AttributeError, TypeError) as e:
                    # N·∫øu jobs dict c√≥ v·∫•n ƒë·ªÅ, log v√† continue
                    self.logger.log_step(
                        step="SCHEDULER_LOOP",
                        result="WARNING",
                        error=f"Error checking running jobs: {safe_get_exception_message(e)}",
                        error_type=safe_get_exception_type_name(e)
                    )
                    running_jobs = []
                
                if running_jobs:
                    # C√≥ job ƒëang ch·∫°y, kh√¥ng ch·∫°y job m·ªõi
                    # Ch·ªù job hi·ªán t·∫°i ho√†n th√†nh ho·∫∑c b·ªã recover
                    self.logger.log_step(
                        step="SCHEDULER_LOOP",
                        result="INFO",
                        note=f"Job ƒëang ch·∫°y, ch·ªù ho√†n th√†nh. Running jobs: {len(running_jobs)}",
                        running_job_ids=[j.job_id for j in running_jobs]
                    )
                    await asyncio.sleep(10)  # Ch·ªù ng·∫Øn tr∆∞·ªõc khi check l·∫°i
                    continue
                
                # Check running flag l·∫°i tr∆∞·ªõc khi ch·∫°y job
                if not running_flag_getter():
                    self.logger.log_step(
                        step="SCHEDULER_LOOP",
                        result="INFO",
                        note="Scheduler running flag set to False, exiting loop before running job"
                    )
                    break
                
                # Reload jobs t·ª´ storage ƒë·ªÉ pick up jobs m·ªõi (m·ªói 30 gi√¢y)
                # B·∫¢O V·ªÜ: Kh√¥ng reload ngay sau khi save ƒë·ªÉ tr√°nh race condition
                if reload_jobs_callback:
                    try:
                        # Check if we need to reload (every 30 seconds)
                        if not hasattr(self, '_last_reload_time'):
                            self._last_reload_time = datetime.now()
                        
                        # Check if we just saved jobs (avoid reload immediately after save)
                        # L·∫•y _last_save_time t·ª´ scheduler ho·∫∑c t·ª´ executor
                        if get_last_save_time:
                            last_save_time = get_last_save_time()
                        else:
                            last_save_time = getattr(self, '_last_save_time', datetime.min)
                        
                        elapsed = (datetime.now() - self._last_reload_time).total_seconds()
                        time_since_save = (datetime.now() - last_save_time).total_seconds()
                        
                        # Reload every 30 seconds, but NOT within 2 seconds after save
                        # Tr√°nh race condition: save ‚Üí reload ngay l·∫≠p t·ª©c ‚Üí overwrite COMPLETED
                        if elapsed >= 30 and time_since_save >= 2:
                            reload_jobs_callback()  # Reload jobs t·ª´ storage
                            self._last_reload_time = datetime.now()
                            self.logger.log_step(
                                step="SCHEDULER_LOOP",
                                result="INFO",
                                note="Reloaded jobs from storage to pick up new jobs"
                            )
                    except Exception as e:
                        # Log nh∆∞ng kh√¥ng block
                        self.logger.log_step(
                            step="SCHEDULER_LOOP",
                            result="WARNING",
                            error=f"Error reloading jobs: {safe_get_exception_message(e)}",
                            error_type=safe_get_exception_type_name(e)
                        )
                
                # L·∫•y jobs s·∫µn s√†ng ch·∫°y v·ªõi error handling
                try:
                    ready_jobs = get_ready_jobs()
                    # #region agent log - Debug scheduler_loop get_ready_jobs
                    import json
                    import os
                    log_path = os.path.join(os.path.expanduser("~"), "threads", ".cursor", "debug.log")
                    with open(log_path, 'a', encoding='utf-8') as f:
                        f.write(json.dumps({"location":"execution.py:scheduler_loop","message":"get_ready_jobs result","data":{"ready_jobs_count":len(ready_jobs) if ready_jobs else 0,"ready_job_ids":[getattr(j,'job_id','unknown')[:8] for j in ready_jobs[:3]] if ready_jobs else [],"running":running_flag_getter()},"timestamp":int(__import__('time').time()*1000),"sessionId":"debug-session","runId":"run1","hypothesisId":"F"})+'\n')
                    # #endregion
                except Exception as e:
                    self.logger.log_step(
                        step="SCHEDULER_LOOP",
                        result="WARNING",
                        error=f"Error in get_ready_jobs: {safe_get_exception_message(e)}",
                        error_type=safe_get_exception_type_name(e)
                    )
                    ready_jobs = []
                
                if ready_jobs:
                    # Ch·∫°y job c√≥ priority cao nh·∫•t
                    try:
                        job = ready_jobs[0]
                        job_status_before = job.status if hasattr(job, 'status') else None
                        await self.run_job(job, post_callback_factory)
                        
                        # N·∫øu job th√†nh c√¥ng, th√™m delay ƒë·ªÉ ƒë·∫£m b·∫£o action spacing
                        # Delay n√†y gi√∫p tr√°nh b·ªã SafetyGuard ch·∫∑n khi c√≥ nhi·ªÅu jobs c√πng ready
                        job_status_after = job.status if hasattr(job, 'status') else None
                        if job_status_after == JobStatus.COMPLETED:
                            # L·∫•y min_delay t·ª´ SafetyGuard config
                            min_delay_seconds = 5.0  # Default
                            try:
                                from services.safety_guard import SafetyConfig
                                safety_config = SafetyConfig()
                                min_delay_seconds = safety_config.min_delay_between_posts_seconds
                            except Exception:
                                pass
                            
                            # Delay v·ªõi safety buffer (1.5x ƒë·ªÉ ƒë·∫£m b·∫£o an to√†n)
                            delay_seconds = min_delay_seconds * 1.5
                            
                            # Ch·ªâ delay n·∫øu c√≥ jobs kh√°c c√πng ready cho c√πng account
                            has_more_ready_jobs_same_account = False
                            if len(ready_jobs) > 1:
                                for other_job in ready_jobs[1:]:
                                    if (hasattr(other_job, 'account_id') and 
                                        hasattr(job, 'account_id') and 
                                        other_job.account_id == job.account_id):
                                        has_more_ready_jobs_same_account = True
                                        break
                            
                            if has_more_ready_jobs_same_account:
                                self.logger.log_step(
                                    step="SCHEDULER_LOOP",
                                    result="INFO",
                                    note=f"Job completed successfully. Delaying {delay_seconds:.1f}s before next job to ensure action spacing.",
                                    account_id=job.account_id if hasattr(job, 'account_id') else None,
                                    delay_seconds=delay_seconds
                                )
                                await asyncio.sleep(delay_seconds)
                    except Exception as e:
                        # Log error nh∆∞ng continue loop
                        self.logger.log_step(
                            step="SCHEDULER_LOOP",
                            result="ERROR",
                            error=f"Error running job {job.job_id if hasattr(job, 'job_id') else 'unknown'}: {safe_get_exception_message(e)}",
                            error_type=safe_get_exception_type_name(e)
                        )
                else:
                    # Kh√¥ng c√≥ job n√†o s·∫µn s√†ng
                    # Ki·ªÉm tra xem c√≥ jobs n√†o c√≤n active (pending, scheduled, running) kh√¥ng
                    has_active_jobs = False
                    try:
                        active_statuses = [JobStatus.PENDING, JobStatus.SCHEDULED, JobStatus.RUNNING]
                        for job in self.jobs.values():
                            try:
                                if hasattr(job, 'status') and job.status in active_statuses:
                                    has_active_jobs = True
                                    break
                            except (AttributeError, TypeError):
                                continue
                    except (AttributeError, TypeError):
                        # N·∫øu kh√¥ng th·ªÉ check, gi·∫£ ƒë·ªãnh c√≥ active jobs ƒë·ªÉ an to√†n
                        has_active_jobs = True
                    
                    if has_active_jobs:
                        # C√≥ jobs active, ch·ªù ng·∫Øn (30s) r·ªìi check l·∫°i
                        self.logger.log_step(
                            step="SCHEDULER_LOOP",
                            result="INFO",
                            note="Kh√¥ng c√≥ job n√†o s·∫µn s√†ng, nh∆∞ng v·∫´n c√≤n jobs active. Ch·ªù 30s..."
                        )
                        for _ in range(30):
                            if not running_flag_getter():
                                break
                            await asyncio.sleep(1)
                    else:
                        # Kh√¥ng c√≤n jobs active n√†o, ch·ªù l√¢u h∆°n (5 ph√∫t) ƒë·ªÉ ti·∫øt ki·ªám t√†i nguy√™n
                        self.logger.log_step(
                            step="SCHEDULER_LOOP",
                            result="INFO",
                            note="Kh√¥ng c√≤n jobs active n√†o. Ch·ªù 5 ph√∫t tr∆∞·ªõc khi check l·∫°i..."
                        )
                        for _ in range(300):  # 5 ph√∫t = 300 gi√¢y
                            if not running_flag_getter():
                                break
                            await asyncio.sleep(1)
            
            except asyncio.CancelledError:
                # Scheduler ƒëang ƒë∆∞·ª£c stop, log v√† re-raise
                self.logger.log_step(
                    step="SCHEDULER_LOOP",
                    result="INFO",
                    note="Scheduler loop cancelled"
                )
                # Set running = False ƒë·ªÉ ƒë·∫£m b·∫£o loop kh√¥ng ti·∫øp t·ª•c
                running_flag_setter(False)
                # Log STOP_SCHEDULER ngay t·∫°i ƒë√¢y ƒë·ªÉ ƒë·∫£m b·∫£o log ƒë∆∞·ª£c ghi
                # (v√¨ stop() c√≥ th·ªÉ kh√¥ng ƒë∆∞·ª£c g·ªçi n·∫øu exception ƒë∆∞·ª£c raise tr∆∞·ªõc)
                self.logger.log_step(
                    step="STOP_SCHEDULER",
                    result="INFO",
                    note="Scheduler loop cancelled, will be stopped"
                )
                # Force flush log handlers ƒë·ªÉ ƒë·∫£m b·∫£o log ƒë∆∞·ª£c ghi ngay
                try:
                    for handler in self.logger.logger.handlers:
                        handler.flush()
                except Exception as e:
                    # Log error nh∆∞ng kh√¥ng raise
                    print(f"WARNING: Error flushing log handlers: {str(e)}")
                
                # Save jobs tr∆∞·ªõc khi exit v·ªõi error handling
                try:
                    self.save_jobs()
                    # Track save time ƒë·ªÉ tr√°nh reload ngay sau save
                    self._last_save_time = datetime.now()
                except Exception as e:
                    # Log error nh∆∞ng kh√¥ng raise (ƒë·ªÉ ƒë·∫£m b·∫£o loop c√≥ th·ªÉ exit)
                    self.logger.log_step(
                        step="STOP_SCHEDULER",
                        result="WARNING",
                        error=f"Failed to save jobs on cancel: {safe_get_exception_message(e)}",
                        error_type=safe_get_exception_type_name(e)
                    )
                raise
            except Exception as e:
                self.logger.log_step(
                    step="SCHEDULER_LOOP",
                    result="ERROR",
                    error=safe_get_exception_message(e),
                    error_type=safe_get_exception_type_name(e)
                )
                # Ch·ªù 10s tr∆∞·ªõc khi ti·∫øp t·ª•c ƒë·ªÉ tr√°nh loop l·ªói li√™n t·ª•c
                await asyncio.sleep(10)

